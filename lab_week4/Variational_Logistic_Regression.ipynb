{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "cgxu7lLYb9W6"
      },
      "source": [
        "# Advanced Statistical Inference -- Variational Inference for Bayesian Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "LdC67PhNb9W7"
      },
      "source": [
        "In this notebook, you will learn how to implement the (stochastic) variational inference algorithm.\n",
        "The gist below will serve you as a refresh on variational inference.\n",
        "For additional information, please check the lecture notes.\n",
        "\n",
        "In the general setting, given a probabilistic model with observations $\\{\\boldsymbol{X},\\boldsymbol{y}\\}$, model parameters $\\boldsymbol{w}$ and likelihood $p(\\boldsymbol{y}|\\boldsymbol{X}, \\boldsymbol{w})$, by introducing an approximate posterior distribution $q_\\theta(\\boldsymbol{w})$ with parameters $\\theta$, the variational lower bound to the log-marginal likelihood is defined as\n",
        "\n",
        "\n",
        "$$\\mathrm{KL}[{q_\\theta(\\boldsymbol{w})}||{p(\\boldsymbol{w}|\\boldsymbol{X},\\boldsymbol{y})}] = -\\mathbb{E}_{q_{\\theta}}\\log p(\\boldsymbol{y}|\\boldsymbol{X}, \\boldsymbol{w}) +  \\mathrm{KL}[{q_{\\theta}(\\boldsymbol{w})}||{p(\\boldsymbol{w})}] + \\log p(\\boldsymbol{y}|\\boldsymbol{X}) $$\n",
        "\n",
        "\n",
        "The objective is then to maximize this variational bound (or evidence lower bound) - the ELBO:\n",
        "\n",
        "$$\n",
        "      \\mathcal{L}(\\theta) = \\underbrace{\\mathbb{E}_{q_{\\theta}}\\log p(\\boldsymbol{y}|\\boldsymbol{X}, \\boldsymbol{w})}_\\text{Expected loglikelihood} -  \\mathrm{KL}[{q_{\\theta}(\\boldsymbol{w})}||{p(\\boldsymbol{w})}]\n",
        "$$\n",
        "\n",
        "The analytic evaluation of the ELBO is generally still untractable due to the presence of the expected loglikelihood under the variational distribution (in the majority of  cases the rightmost KL is tractable).\n",
        "This is commonly overcome by sampling $N_\\mathrm{MC}$ times from $q_\\theta$  using the reparameterization trick\n",
        "\n",
        "$$\n",
        "    \\mathbb{E}_{q_{\\theta}}\\log p(\\boldsymbol{y}|\\boldsymbol{X}, \\boldsymbol{w}) \\approx \\dfrac{1}{N_\\mathrm{MC}} \\sum_{\\tilde{\\boldsymbol{w}}_i\\sim q_\\theta} \\log p(\\boldsymbol{y}|\\boldsymbol{X}, \\tilde{\\boldsymbol{w}}_i)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GPagThDcb9W7"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import rc\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "dark = True\n",
        "colab = \"google.colab\" in str(get_ipython())\n",
        "preamble = r\"\"\"\\renewcommand{\\familydefault}{\\sfdefault}\\usepackage{sansmath}\n",
        "\\usepackage{FiraSans}\\sansmath\\usepackage{amsmath}\"\"\"\n",
        "\n",
        "rc(\"font\", **{\"family\": \"sans-serif\", \"sans-serif\": \"DejaVu Sans\"})\n",
        "rc(\"text\", **{\"usetex\": False, \"latex.preamble\": preamble})\n",
        "rc(\"figure\", **{\"dpi\": 200})\n",
        "rc(\n",
        "    \"axes\",\n",
        "    **{\"spines.right\": False, \"spines.top\": False, \"xmargin\": 0.0, \"ymargin\": 0.05}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "GmmDLd0Bb9W8"
      },
      "source": [
        "## Library and coding\n",
        "\n",
        "This lab is heavily built on JAX. You already used JAX during the lab on Gaussian process regression when you took advantage of the automatic differentation engine to optimize the kernel parameters, without manually writing the derivatives by hand.\n",
        "This time, we will this same auto-diff engine to optimize our variational objective, but we will also take advantage of another key charateristic of JAX: automatic vectorization. This will allow us to efficiently parallelize the computation of the expected likelihood.\n",
        "\n",
        "\n",
        "Below, you have a short tutorial on how this works.\n",
        "\n",
        "**Note**: This notebook is computationally more intensive than the previous ones (cells may run for up to 1 minute). If you are using Google Colab, you can speed up the computation by switching to a GPU runtime. Behind the scenes, JAX will automatically take care of the GPU acceleration for you.\n",
        "\n",
        "Consider the following simple code that computes the convolution of two one-dimensional vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbYJhAiab9W8",
        "outputId": "4e432896-435c-4e44-b57e-78ed22cf029b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = [0. 1. 2. 3. 4.]\n",
            "w = [2. 3. 4.]\n",
            "y = [11. 20. 29.]\n"
          ]
        }
      ],
      "source": [
        "x = jnp.array([0.0, 1.0, 2.0, 3.0, 4.0])\n",
        "w = jnp.array([2.0, 3.0, 4.0])\n",
        "\n",
        "\n",
        "def convolve(x, w):\n",
        "    y = []\n",
        "    for i in range(1, len(x) - 1):\n",
        "        y.append(jnp.dot(x[i - 1 : i + 2], w))\n",
        "    return jnp.array(y)\n",
        "\n",
        "\n",
        "y = convolve(x, w)\n",
        "\n",
        "print(f\"x = {x}\\nw = {w}\\ny = {y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upbGPertb9W8"
      },
      "source": [
        "Suppose we would like to apply this function to a batch of weights `w` to a batch of vectors `x`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0clziAn7b9W8",
        "outputId": "1900c2bb-2106-4fb0-b710-3408cb0edbbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = \n",
            "[[0. 1. 2. 3. 4.]\n",
            " [0. 2. 4. 6. 8.]]\n",
            "\n",
            "W =\n",
            "[[2. 3. 4.]\n",
            " [4. 6. 8.]]\n"
          ]
        }
      ],
      "source": [
        "X = jnp.stack([x, 2 * x])\n",
        "W = jnp.stack([w, 2 * w])\n",
        "\n",
        "print(f\"X = \\n{X}\\n\\nW =\\n{W}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0pHrZTlb9W8"
      },
      "source": [
        "The most naive option would be to simply loop over the batch in Python and then stack the results; this produces the correct result, however it is not very efficient.\n",
        "In order to batch the computation efficiently, you would normally have to rewrite the function manually to ensure it is done in vectorized form.\n",
        "This is not particularly difficult to implement for this particular example, but does involve changing how the function treats indices, axes, and other parts of the input.\n",
        "Such re-implementation can become messy to understand and error-prone; fortunately JAX provides another way.\n",
        "In JAX, the `jax.vmap` transformation is designed to generate such a vectorized implementation of a function automatically:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLz0Uu25b9W8",
        "outputId": "adbab676-0b22-476d-b431-3b44a141e791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = \n",
            "[[0. 1. 2. 3. 4.]\n",
            " [0. 2. 4. 6. 8.]]\n",
            "W =  \n",
            "[[2. 3. 4.]\n",
            " [4. 6. 8.]]\n",
            "Y =  \n",
            "[[ 11.  20.  29.]\n",
            " [ 44.  80. 116.]]\n"
          ]
        }
      ],
      "source": [
        "Y = jax.vmap(convolve)(X, W)\n",
        "print(f\"X = \\n{X}\\nW =  \\n{W}\\nY =  \\n{Y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB7-bhP_b9W8"
      },
      "source": [
        "Additional you can control what to vectorize using `in_axes=[...]`. For example, if you would like to convolve to a single set of weights `w` with a batch of vectors `X` you need to choose `in_axes=[0, None]`: this means \"vectorize on the axis 0 of the first arg but do *not* vectorize on the second arg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy1K8aTvb9W9",
        "outputId": "bee66a10-fecd-4188-fead-80c18402cc4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = \n",
            "[[0. 1. 2. 3. 4.]\n",
            " [0. 2. 4. 6. 8.]]\n",
            "w = \n",
            "[2. 3. 4.]\n",
            "Y =  \n",
            "[[11. 20. 29.]\n",
            " [22. 40. 58.]]\n"
          ]
        }
      ],
      "source": [
        "Y = jax.vmap(convolve, in_axes=[0, None])(X, w)\n",
        "print(f\"X = \\n{X}\\nw = \\n{w}\\nY =  \\n{Y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcbJhk5nb9W9"
      },
      "source": [
        "Finally, this `vmap` can be also used as decorator, thus keeping the code cleaner\n",
        "\n",
        "The Pythonic way to improve the code is to use a decorator and a `partial` function to specify the arguments that should be vectorized.\n",
        "This is a very powerful feature of JAX, and it is used extensively in the code below.\n",
        "The `partial` function allows you to specify the arguments of `vmap` (in this case the `in_axes` argument) without having to rewrite the function itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68fyCY7Bb9W9",
        "outputId": "94c1fc8c-0d10-4b87-b098-3bbbcecd6588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = \n",
            "[[0. 1. 2. 3. 4.]\n",
            " [0. 2. 4. 6. 8.]]\n",
            "w =\n",
            " [2. 3. 4.]\n",
            "Y =  \n",
            "[[11. 20. 29.]\n",
            " [22. 40. 58.]]\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "\n",
        "@partial(jax.vmap, in_axes=[0, None])\n",
        "def convolve(x, w):\n",
        "    y = []\n",
        "    for i in range(1, len(x) - 1):\n",
        "        y.append(jnp.dot(x[i - 1 : i + 2], w))\n",
        "    return jnp.array(y)\n",
        "\n",
        "\n",
        "Y = convolve(X, w)\n",
        "print(f\"X = \\n{X}\\nw =\\n {w}\\nY =  \\n{Y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fasv4xARb9W9"
      },
      "source": [
        "In just 1 line of code, we have vectorized the function with respet to one of its arguments, without having to change the function itself.\n",
        "\n",
        "You can build very complex functions using this approach: just start from the basic building blocks and use `vmap` to vectorize them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "siOSftrRb9W-"
      },
      "source": [
        "### Random number generation in JAX\n",
        "To fully exploit the automatic vectorization of JAX, we will need to switch from the Numpy's random generation to JAX's.\n",
        "The main difference is that JAX is explicit on the definition and usage of the random seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1Rq1oejb9W-",
        "outputId": "a7d4ba79-b9f9-47c9-9e49-d28ba5153629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.947667\n"
          ]
        }
      ],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "print(jax.random.uniform(rng))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG-Az7CLb9W-"
      },
      "source": [
        "This also means that in order to have \"true\" random number generation, we need to manually advance the random seed. **The rule of thumb is: never reuse keys (unless you want identical outputs).**\n",
        "In order to generate different and independent samples, you must `split()` the key *yourself* whenever you want to call a random function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlRDs25qb9W-",
        "outputId": "16fe66da-df80-43d2-c3bf-95502b10df6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rng [0 0] --> uniform 0.947667\n",
            "    \\---SPLIT --> new_rng [ 928981903 3453687069] --> uniform 0.0072938204\n"
          ]
        }
      ],
      "source": [
        "print(\"rng\", rng, \"--> uniform\", jax.random.uniform(rng))\n",
        "rng, new_rng = jax.random.split(rng)\n",
        "normal_sample = jax.random.uniform(new_rng)\n",
        "print(r\"    \\---SPLIT --> new_rng\", new_rng, \"--> uniform\", jax.random.uniform(new_rng))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3QleanRb9W-"
      },
      "source": [
        "While all this sounds exceedingly over-complicated, it also allows to very easily vectorize using `jax.vmap` functions that works on random samples. Take a look at the next cell and try to understand what is going on here.\n",
        "\n",
        "“Apply take_square to each row (key) of multiple_rng, in parallel.”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3PdU87Pb9W-",
        "outputId": "c172903d-788d-42ce-a2f7-088a1e7df9ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.07993058 0.01087648 0.05220539 0.40073746 0.80360603 0.7290857\n",
            " 0.06019844 0.01839877 0.09836758 0.11087253]\n"
          ]
        }
      ],
      "source": [
        "def take_square(rng):\n",
        "    x = jax.random.uniform(rng)\n",
        "    return x**2\n",
        "\n",
        "\n",
        "multiple_rng = jax.random.split(rng, 10)\n",
        "print(jax.vmap(take_square)(multiple_rng))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMHTxDh0b9W-"
      },
      "source": [
        "**Exercise**: Test if you understood the code above. Write a function that take a random key and a constant, generates a Gaussian random variable with mean 0 and variance 1, adds the contant, and returns the result.\n",
        "Then, use `jax.vmap` to generate a batch of 20 random variables, with the same constant added to each of them (hint: you need to vmap on the first argument, not the second one). Try to use the decorator style, as shown above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWh8TJtDb9W-",
        "outputId": "9192bb09-5101-4b11-ace3-82c8f175bbd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.42522   3.7425222 4.2561545 5.3399115 6.2615285 6.053156  4.310816\n",
            " 3.89989   4.51443   4.568288  4.6577816 6.2780547 5.8579965 6.1685214\n",
            " 4.2157717 3.9415426 3.952939  5.948308  4.6368456 6.763179 ]\n"
          ]
        }
      ],
      "source": [
        "## input: random key and a constant\n",
        "# method:\n",
        "# - generate gaussian random variable, mean 0 and variance 1.\n",
        "# - add constant\n",
        "# - return result\n",
        "\n",
        "# use jax.vmap to generate batch of 20 random variables\n",
        "# add the same constant to each of them\n",
        "\n",
        "# hint: use vmap on first argument, not the second one.\n",
        "\n",
        "#@<something>(...)\n",
        "@partial(jax.vmap, in_axes=[0, None])\n",
        "def test_function(rng, k):\n",
        "  return jax.random.normal(rng) + k\n",
        "\n",
        "multiple_rng = jax.random.split(rng, 20)\n",
        "# Pass k as a positional argument to match in_axes=[0, None]\n",
        "out = test_function(multiple_rng, 5)\n",
        "\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKjhCQ2Eb9W-"
      },
      "source": [
        "# 1. Setup and data\n",
        "\n",
        "Similarly to the previous lab, you’re going to implement the VI algorithm described in the lecture for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [],
        "id": "aK9YDptbb9W-"
      },
      "outputs": [],
      "source": [
        "def plot_data(X, y, ax):\n",
        "    mask = y == 1\n",
        "    config = dict(edgecolor=\"black\", linewidth=1, zorder=10)\n",
        "    ax.scatter(*X[mask].T, label=\"Class 1\", facecolor=\"tab:blue\", **config)\n",
        "    ax.scatter(*X[~mask].T, label=\"Class 0\", facecolor=\"tab:orange\", **config)\n",
        "\n",
        "\n",
        "def get_grid(xlim=(-3, 3), ylim=None, N=100):\n",
        "    if ylim is None:\n",
        "        ylim = xlim\n",
        "    x_grid = np.linspace(*xlim, N)\n",
        "    y_grid = np.linspace(*ylim, N)\n",
        "    xx, yy = np.meshgrid(x_grid, y_grid)\n",
        "    X_plot = np.vstack((xx.flatten(), yy.flatten())).T\n",
        "    return xx, yy, X_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "AIyHSuqlb9W-",
        "outputId": "93406f6a-e147-4550-e89f-e5d5075f9171"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "data = np.loadtxt(\"https://github.com/eurecom-ds/asi-labs/raw/refs/heads/master/lab_week2/binaryclass2.csv\", delimiter=\",\")\n",
        "X = data[..., :-1]\n",
        "y = data[..., -1]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=[5, 3])\n",
        "plot_data(X, y, ax)\n",
        "ax.set_title(\"Binary classification\")\n",
        "ax.legend()\n",
        "ax.set_xlim(-6, 6), ax.set_ylim(-6, 6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0WIA0qib9W_"
      },
      "source": [
        "Let's start by defining some probability distributions that we will need in this notebook.\n",
        "First, the Bernoulli distribution.\n",
        "\n",
        "**Exercise:**\n",
        "Complete the following class to compute the logdensity of the Bernoulli distribution. Since we will be taking gradients of this likelihood, it's possible that during optimization $p$ becomes (down to machine precision) exactly 0 or 1, which makes the evaluation of the logarithm troublesome. To avoide this behavior, simply add a small quantity (like `1e-6`) before computing the log."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ln_89d0Hb9W_"
      },
      "outputs": [],
      "source": [
        "def bernoulli_logdensity(y, p):\n",
        "    epsilon = 1e-6\n",
        "    p = jnp.clip(p, epsilon, 1 - epsilon)\n",
        "    # Bernoulli log-likelihood: y * log(p) + (1 - y) * log(1 - p)\n",
        "    out = y * jnp.log(p) + (1 - y) * jnp.log(1 - p)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1glbhvyxb9W_"
      },
      "source": [
        "Now let's move to the Gaussian distribution. Note that the parameter $\\sigma^2$ is always expected to be positive while it is possible that the optimisation algorithm attempts to evaluate the log-likelihood in regions of the parameter space where one or more of these parameters are negative, leading to numerical issues.\n",
        "A commonly-used technique to enforce this condition is to work with a transformed version of parameters using the logarithm transformation.\n",
        "In particular, define $\\psi = \\log\\sigma^2$.\n",
        "So remember to take the exponential of $\\psi$ if you want to use $\\sigma^2$.\n",
        "\n",
        "The following class implements the Gaussian distribution, with a vector of means and a vector of log-variances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "s2Z5YRIZb9W_"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from typing import NamedTuple\n",
        "\n",
        "\n",
        "class GaussianDiagonal(NamedTuple):\n",
        "    mean: jnp.array\n",
        "    log_var: jnp.array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49qswl-cb9W_"
      },
      "source": [
        "**Exercise**: Complete the next function to generate *one* sample from a Gaussian distribution using the reparameterization trick. Remember $p(\\boldsymbol z) = p(t(\\boldsymbol \\varepsilon;\\boldsymbol \\theta))$ where $t(\\cdot) = \\boldsymbol \\mu + \\boldsymbol \\sigma \\odot \\boldsymbol \\varepsilon$ and $\\boldsymbol \\varepsilon \\sim \\mathcal{N}(\\boldsymbol 0, \\boldsymbol I)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cAXZWeeBb9W_"
      },
      "outputs": [],
      "source": [
        "def sample_gaussian_diagonal(rng, params):\n",
        "    \"\"\"\n",
        "    Sample from a Gaussian distribution with diagonal covariance.\n",
        "\n",
        "    Args:\n",
        "        rng: Random number generator key.\n",
        "        params: A named tuple containing the mean and log variance of the Gaussian.\n",
        "            mean: Mean of the Gaussian distribution.\n",
        "            log_var: Log variance of the Gaussian distribution.\n",
        "    \"\"\"\n",
        "    eps = jax.random.normal(rng, shape=params.mean.shape)\n",
        "    # invert the log-variance to get the standard deviation std\n",
        "    std = np.exp(params.log_var * 0.5)\n",
        "    # out = params.mean + params.variance * eps (standard normal noice)\n",
        "    out = params.mean + std * eps\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrqodAUOb9W_"
      },
      "source": [
        "**Exercise**: Create a Gaussian with two components with $\\mathcal{N}(\\boldsymbol 0, \\boldsymbol 1)$ and get one sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5jqIJxX3b9W_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448907eb-1110-49ca-9427-3d19dc669f2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.6226422 2.0252647]\n"
          ]
        }
      ],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "p_params = GaussianDiagonal(jnp.zeros(2), jnp.zeros(2))\n",
        "print(sample_gaussian_diagonal(rng, p_params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaQxb50Kb9W_"
      },
      "source": [
        "# 2. KL Divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKW4Wbdyb9W_"
      },
      "source": [
        "The expression of the KL divergence between multivariate Gaussians $q = \\mathcal{N}(\\boldsymbol{\\mu}_q, \\boldsymbol\\Sigma_q)$ and $p = \\mathcal{N}(\\boldsymbol{\\mu}_p, \\boldsymbol\\Sigma_p)$ is as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathrm{KL}[q || p] =\n",
        "\\frac{1}{2} \\mathrm{Tr}(\\boldsymbol\\Sigma_p^{-1} \\boldsymbol\\Sigma_q)\n",
        "+ \\frac{1}{2} (\\boldsymbol\\mu_p - \\boldsymbol\\mu_q)^{\\top} \\boldsymbol\\Sigma_1^{-1} (\\boldsymbol\\mu_p - \\boldsymbol\\mu_q)\n",
        "- \\frac{D}{2}\n",
        "+ \\frac{1}{2} \\log\\left( \\frac{\\mathrm{det}\\boldsymbol\\Sigma_p}{\\mathrm{det}\\boldsymbol\\Sigma_q} \\right)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "This formula simplifies when the two Gaussians have diagonal covariance, i.e. $q = \\mathcal{N}(\\boldsymbol{\\mu}_q, \\boldsymbol{\\sigma}^2_q\\mathrm{I})$ and $p = \\mathcal{N}(\\boldsymbol{\\mu}_p, \\boldsymbol{\\sigma}^2_p\\mathrm{I})$,\n",
        "\n",
        "$$\n",
        "\\mathrm{KL}[q || p] =  \\frac{1}{2} \\sum\\left( \\log \\frac{\\sigma^2_p}{\\sigma^2_q} + \\frac{\\sigma_q^2 + (\\mu_q - \\mu_p)^2}{\\sigma_p^2} - 1 \\right)\n",
        "$$\n",
        "\n",
        "\n",
        "**Exercise:**\n",
        "Complete the next function to compute the KL divergence between two multivariate Gaussian distribution with diagonal covariance. *Note:* Since we have parameterized the Gaussian distribution with the logvariance, the formula above can be simplified even further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7HASilc2b9W_"
      },
      "outputs": [],
      "source": [
        "def kl_diag_diag(q_params: GaussianDiagonal, p_params: GaussianDiagonal):\n",
        "    \"\"\"\n",
        "    Compute the KL divergence between two Gaussian distributions with diagonal covariance.\n",
        "\n",
        "    Args:\n",
        "        q_params: A named tuple containing the mean and log variance of the first Gaussian.\n",
        "        p_params: A named tuple containing the mean and log variance of the second Gaussian.\n",
        "    \"\"\"\n",
        "    assert isinstance(q_params, GaussianDiagonal)\n",
        "    assert isinstance(p_params, GaussianDiagonal)\n",
        "\n",
        "    p_std2 = np.exp(p_params.log_var)\n",
        "    q_std2 = np.exp(q_params.log_var)\n",
        "\n",
        "    kl = 0.5 * np.sum(np.log((p_std2 / q_std2)) + ((q_std2 + (q_params.mean - p_params.mean) ** 2) / (p_std2 ** 2)) - 1)\n",
        "    return kl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijKoBEJ_b9XA"
      },
      "source": [
        "**Exercise:**\n",
        "Create two identical Gaussian distributions and compute the KL divergence using the function. What's the result? Is it what you were expecting?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: The KL is the same for the two Gaussians. This was expected, since KL divergence is a measure of the difference between two probability distributions."
      ],
      "metadata": {
        "id": "B4C3Rk8vZ4tZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_uL_wOrOb9XA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc2c6fc-a170-458f-e6ba-44f30ae91f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KL = 0.0\n"
          ]
        }
      ],
      "source": [
        "p_params = GaussianDiagonal(jnp.zeros(2), jnp.zeros(2))\n",
        "q_params = GaussianDiagonal(jnp.zeros(2), jnp.zeros(2))\n",
        "\n",
        "print(\"KL =\", kl_diag_diag(q_params, p_params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6ehC9Zeb9XA"
      },
      "source": [
        "# 3. Model\n",
        "\n",
        "Now we can move to design the model. We will use a simple logistic regression very similarly to what done in the previous MCMC lab.\n",
        "This very simple model computes $h(\\boldsymbol{x}) = h(\\boldsymbol{w}^\\top\\boldsymbol{x})$, where $h(\\cdot)$ is the logistic function.\n",
        "\n",
        "**Exercise:**\n",
        "Complete the next two functions to compute (i) the logistic function and (ii) the output of the model, given a particular choice of $\\boldsymbol w$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BsjSv6J_b9XD"
      },
      "outputs": [],
      "source": [
        "def logistic(z):\n",
        "    \"\"\"\n",
        "    Logistic (sigmoid) function. Defined as h(z) = 1 + exp(-z)^-1\n",
        "    \"\"\"\n",
        "    out = 1 / ( 1 + jnp.exp(-z))\n",
        "    return out\n",
        "\n",
        "\n",
        "def model(w, X):\n",
        "    \"\"\"\n",
        "    Logistic regression model.\n",
        "    Args:\n",
        "        w: Model parameters.\n",
        "        X: Input data.\n",
        "    \"\"\"\n",
        "    data = jnp.dot(w.T, X)\n",
        "    out = logistic(data)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "VbicY0cwb9XD"
      },
      "source": [
        "# 4. Variational objective\n",
        "\n",
        "The objective is to maximize this variational bound:\n",
        "$$\n",
        "      \\mathcal{L}(\\theta) = \\underbrace{\\mathbb{E}_{q_{\\theta}}\\log p(\\boldsymbol{y}|\\boldsymbol{X}, \\boldsymbol{w})}_\\text{Expected loglikelihood} -\\mathrm{KL}[{q_{\\theta}(\\boldsymbol{w})}||{p(\\boldsymbol{w})}]\n",
        "$$\n",
        "\n",
        "**Exercise:**\n",
        "Complete the next cell to compute the ELBO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CgmZcT7b9XD"
      },
      "outputs": [],
      "source": [
        "def create_elbo_fn(sample_fn, likelihood_fn, kl_divergence_fn):\n",
        "    \"\"\"\n",
        "    Create a function to compute the ELBO, given the function to sample\n",
        "    from the posterior, the likelihood function and the KL divergence\n",
        "\n",
        "    Args:\n",
        "        sample_fn: Function to sample from the posterior.\n",
        "        likelihood_fn: Likelihood function.\n",
        "        kl_divergence_fn: KL divergence function\n",
        "    \"\"\"\n",
        "\n",
        "    @partial(jax.vmap, in_axes=[0, None, None, None])\n",
        "    def likelihood_sample_fn(rng, q_params, X, y):\n",
        "        \"\"\"\n",
        "        Compute the log-likelihood with one Monte Carlo sample of the posterior\n",
        "        The function is decorated to vectorized multiple MC sample automatically\n",
        "\n",
        "        Args:\n",
        "            rng: Random number generator key.\n",
        "            q_params: Parameters of the posterior distribution.\n",
        "            X: Input data.\n",
        "            y: Labels.\n",
        "        \"\"\"\n",
        "        # @@ COMPLETE @@\n",
        "        # # Get one sample of w using the sample_fn and the parameters of q\n",
        "        # w =\n",
        "        # # Predict the output using the sample before\n",
        "        # yp =\n",
        "        # # Compute the likelihood and return it (remember that the data points are independent, so the likelihood is the product of the individual likelihoods, which is the ... of the individual log likelihoods)\n",
        "        # ll =\n",
        "        return ll\n",
        "\n",
        "    def elbo_fn(q_params, p_params, rng, X, y, Nmc=1):\n",
        "        \"\"\"\n",
        "        Computes the ELBO with multiple samples\n",
        "\n",
        "        Args:\n",
        "            q_params: Parameters of the posterior distribution.\n",
        "            p_params: Parameters of the prior distribution.\n",
        "            rng: Random number generator key.\n",
        "            X: Input data.\n",
        "            y: Labels.\n",
        "            Nmc: Number of Monte Carlo samples to use for the ELBO estimation.\n",
        "        \"\"\"\n",
        "        # Split the random seed in Nmc times\n",
        "        rng = jax.random.split(rng, Nmc)\n",
        "\n",
        "        # @@ COMPLETE @@\n",
        "        # # Compute the values of the elbo\n",
        "        # likelihood_vals =\n",
        "        # # Compute the expectation (i.e. take the mean)\n",
        "        # expected_likelihood =\n",
        "        # # Compute the KL divergence\n",
        "        # kl =\n",
        "        # # Compute the ELBO\n",
        "        # elbo =\n",
        "\n",
        "        # # Return the ELBO and its two term (used later for logging)\n",
        "        return elbo, (expected_likelihood, kl)\n",
        "\n",
        "    return elbo_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzeozw4-b9XD"
      },
      "source": [
        "**Exercise:**\n",
        "Using the function above, create the function to compute the ELBO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6kHZ_wsb9XD"
      },
      "outputs": [],
      "source": [
        "elbo_fn = create_elbo_fn(\n",
        "    sample_fn=sample_gaussian_diagonal,\n",
        "    kl_divergence_fn=kl_diag_diag,\n",
        "    likelihood_fn=bernoulli_logdensity,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MZ-tbBFb9XD"
      },
      "source": [
        "**Exercise:**\n",
        "Try to compute the variational objective (use 10 Monte Carlo samples)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn8PIUtBb9XD"
      },
      "outputs": [],
      "source": [
        "# @@ COMPLETE @@\n",
        "# elbo, (likelihood, kl) =\n",
        "\n",
        "print(\"ELBO =\", elbo)\n",
        "print(\"Likelihood =\", likelihood)\n",
        "print(\"KL =\", kl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx7Z0bbQb9XD"
      },
      "source": [
        "## 4.1 Analysis of the MC estimate of the ELBO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Siw-h1B2b9XD"
      },
      "source": [
        "Ok, now that everything is done and ready we can start to make some analysis.\n",
        "\n",
        "First of all, as we said we don't have an analytical formula for the variational objective (our loss). We can only access (unbiased) samples, hence the next question.\n",
        "\n",
        "**Exercise:**\n",
        "Try to sample using 100 different random seeds the ELBO with [2, 10, 100, 1000] MC samples and plot their distribution with boxplots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqpZHxItb9XD"
      },
      "outputs": [],
      "source": [
        "elbo_samples = pd.DataFrame()\n",
        "n_repetition = 100\n",
        "\n",
        "for Nmc in [2, 10, 100, 1000]:\n",
        "    elbo_samples[Nmc] = np.stack(\n",
        "        [\n",
        "            elbo_fn(q_params, p_params, jax.random.PRNGKey(i), X, y, Nmc=Nmc)[0]\n",
        "            for i in range(n_repetition)\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYdqGy2lb9XE"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=[8, 4])\n",
        "sns.boxplot(data=elbo_samples, whis=np.inf)\n",
        "ax.set_title(\"Samples of the MC estimate of the ELBO\")\n",
        "ax.set_xlabel(\"Number of MC samples\")\n",
        "ax.set_ylabel(\"ELBO\")\n",
        "ax.margins(0, 0.05)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_nL4eJTb9XE"
      },
      "source": [
        "We said that, in case of large datasets, this can be computationally challenging, due to the evaluation of the likelihood $N_\\mathrm{MC}$ times.\n",
        "But we know that the ELBO can be approximated even further using mini-batching.\n",
        "Taking a random subset of data $\\mathcal{B}$, the approximation becomes\n",
        "\n",
        "$$\n",
        "    \\mathbb{E}_{q_{\\theta}}\\log p(\\boldsymbol{y}|\\boldsymbol{X}, \\boldsymbol{w}) \\approx \\dfrac{1}{N_\\mathrm{MC}} \\frac{N}{|\\mathcal{B}|}\\sum_{\\tilde{\\boldsymbol{w}}_i\\sim q_\\theta} \\sum_{\\boldsymbol{X}_j, \\boldsymbol{y}_j\\sim\\mathcal{B}} \\log p(\\boldsymbol{y}_j|\\boldsymbol{X}_j, \\tilde{\\boldsymbol{w}}_i)\n",
        "$$\n",
        "\n",
        "This introduces even more variance in the estimate of the ELBO but it allows to scale to (virtually) any sized dataset.\n",
        "You are free to extend this to our ELBO estimator, but for the simple example we are using today, this is not required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YoQBHsrb9XE"
      },
      "source": [
        "# 5. Optimization\n",
        "\n",
        "Ok, now we can move to the optimization of the ELBO:\n",
        "$$\n",
        "\\boldsymbol \\theta_{t+1} = \\boldsymbol \\theta_t + \\text{lr}\\cdot(\\nabla_{\\boldsymbol \\theta} \\mathcal{L})(\\boldsymbol \\theta_t)\n",
        "$$\n",
        "Below you have a simple function to implement this update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBCMm1ugb9XE"
      },
      "outputs": [],
      "source": [
        "def sgd_update(params, gradients, learning_rate=1e-3):\n",
        "    \"\"\"\n",
        "    Perform a stochastic gradient ascent update on the parameters.\n",
        "    Args:\n",
        "        params: Parameters to be updated.\n",
        "        gradients: Gradients of the parameters.\n",
        "        learning_rate: Learning rate for the update.\n",
        "    \"\"\"\n",
        "    updated_params = jax.tree.map(lambda p, g: p + learning_rate * g, params, gradients)\n",
        "    return updated_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuYho8I-b9XF"
      },
      "source": [
        "And here the function to compute the gradient (this function will also be compiled using `jax.jit` for better optimization and faster running times)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWTjJFEqb9XF"
      },
      "outputs": [],
      "source": [
        "grad_elbo_fn = jax.grad(elbo_fn, has_aux=True)\n",
        "grad_elbo_fn = jax.jit(grad_elbo_fn, static_argnames=(\"Nmc\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkHqXcXdb9XF"
      },
      "source": [
        "**Exercise:**\n",
        "Write the training loop to optimize the ELBO (use a learning rate of $10^{-3}$). At every step, store the value of the ELBO, of the expected likelihood and the KL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sP44p2ab9XF"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "q_params = GaussianDiagonal(jnp.zeros(2), jnp.zeros(2))\n",
        "\n",
        "elbo_summary = [] # Keep track of the ELBO\n",
        "lik_summary = [] # Keep track of the likelihood\n",
        "kl_summary = [] # Keep track of the KL divergence\n",
        "\n",
        "for i in tqdm(range(10000), desc=\"Training ELBO\"):\n",
        "    rng, rng2 = jax.random.split(rng)\n",
        "    q_params_grad, (likelihood, kl) = grad_elbo_fn(q_params, p_params, rng2, X, y, 100)\n",
        "    q_params = sgd_update(q_params, q_params_grad, 1e-3)\n",
        "\n",
        "    lik_summary.append(likelihood)\n",
        "    kl_summary.append(kl)\n",
        "    elbo_summary.append(likelihood - kl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LUzxhbXb9XF"
      },
      "outputs": [],
      "source": [
        "print(\"Converged posterior\")\n",
        "print(\"Mean =\", q_params.mean)\n",
        "print(\"Var =\", np.exp(q_params.log_var))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ywDZTRhb9XF"
      },
      "source": [
        "**Exercise:**\n",
        "Assess convergence of the optimization by plotting the three metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RghpTqE2b9XF"
      },
      "outputs": [],
      "source": [
        "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=[8, 2.5])\n",
        "\n",
        "ax0.plot(elbo_summary, label=\"ELBO\")\n",
        "ax1.plot(\n",
        "    lik_summary,\n",
        "    color=\"tab:orange\",\n",
        "    label=r\"$E_{q(\\mathbf{w})} \\log p(\\mathbf{y}|\\mathbf{X},\\mathbf{w})$\",\n",
        ")\n",
        "ax2.plot(\n",
        "    kl_summary,\n",
        "    color=\"tab:green\",\n",
        "    label=r\"$\\mathrm{KL}[{q(\\mathbf{w})}||{p(\\mathbf{w})}]$\",\n",
        ")\n",
        "\n",
        "ax0.semilogx()\n",
        "ax1.semilogx()\n",
        "ax2.semilogx()\n",
        "\n",
        "ax0.axhline(-2.68, color=\"xkcd:red\", label=r\"$\\log p(\\mathbf{y}|\\mathbf{X})$\")\n",
        "ax0.legend(bbox_to_anchor=(1.05, -0.05), loc=\"lower right\")\n",
        "ax1.legend(bbox_to_anchor=(1.05, -0.05), loc=\"lower right\")\n",
        "ax2.legend(bbox_to_anchor=(1.05, -0.05), loc=\"lower right\")\n",
        "\n",
        "ax0.set_xlabel(\"Iteration\")\n",
        "ax1.set_xlabel(\"Iteration\")\n",
        "ax2.set_xlabel(\"Iteration\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFdIsyyqb9XF"
      },
      "source": [
        "**Question:**\n",
        "Analyze the behaviour of these three values and comment the plots. Focus you analysis on the breakdown of the ELBO in its parts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpQ6BmCQb9XF"
      },
      "source": [
        "### Making predictions\n",
        "Now that we have trained the model, we can use it to make predictions on new data.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathbb{E}_{q(\\boldsymbol{w})}h(\\boldsymbol{w}^\\top\\boldsymbol{x}_\\mathrm{new}) = \\int h(\\boldsymbol{w}^\\top\\boldsymbol{x}_\\mathrm{new}) q(\\boldsymbol{w}) \\mathrm{d}\\boldsymbol{w}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "With 1000 samples, compute the probability $P (y_\\mathrm{new} = 1 | \\boldsymbol{x}_\\mathrm{new}, \\boldsymbol{X}, \\boldsymbol{y})$ when $\\boldsymbol{x}_\\mathrm{new} = [2,-4]^\\top$. Compare the result with the number you got from the previous lab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfz0RdULb9XF"
      },
      "outputs": [],
      "source": [
        "def predict_y(sample_fn, q_params, Xt, rng, Nmc=10):\n",
        "    \"\"\"\n",
        "    Compute the outputs of the model by sampling the posterior, then take the expectation\n",
        "\n",
        "    Args:\n",
        "        sample_fn: Function to sample from the posterior.\n",
        "        q_params: Parameters of the posterior distribution.\n",
        "        Xt: Input data for prediction.\n",
        "        rng: Random number generator key.\n",
        "        Nmc: Number of Monte Carlo samples to use for the prediction.\n",
        "    \"\"\"\n",
        "\n",
        "    @jax.vmap\n",
        "    def predict_y_single(rng):\n",
        "        \"\"\"\n",
        "        Predict the output for a single sample of the posterior.\n",
        "\n",
        "        Note: This function is vectorized to allow for multiple samples of the posterior.\n",
        "        \"\"\"\n",
        "        # @@ COMPLETE @@\n",
        "        # w =\n",
        "        # yp =\n",
        "        return yp\n",
        "\n",
        "    rng = jax.random.split(rng, Nmc)\n",
        "    Xt = jnp.atleast_1d(Xt)\n",
        "    # @@ COMPLETE @@\n",
        "    ## Compute the predictions for all the samples\n",
        "    # yp_samples =\n",
        "    ## Compute the mean of the predictions\n",
        "    # yp =\n",
        "    return yp\n",
        "\n",
        "\n",
        "yp = predict_y(sample_gaussian_diagonal, q_params, [2, -4], rng, Nmc=1000)\n",
        "print(yp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTUcIHG-b9XF"
      },
      "source": [
        "**Execise:**\n",
        "Let's now plot the distribution at convergence and the predictions on a grid of points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v07HIc9b9XG"
      },
      "outputs": [],
      "source": [
        "import scipy.stats\n",
        "\n",
        "\n",
        "def plot_gaussian(params, **kwargs):\n",
        "    ax = kwargs.pop(\"ax\", plt.gca())\n",
        "    xx, yy, w_plot = get_grid(xlim=(-1.5, 5.5), N=250)\n",
        "    if isinstance(params, GaussianDiagonal):\n",
        "        cov = np.exp(params.log_var) * np.eye(2)\n",
        "    else:\n",
        "        cov = params.L @ params.L.T\n",
        "    zz = (\n",
        "        scipy.stats.multivariate_normal(mean=params.mean, cov=cov)\n",
        "        .pdf(w_plot)\n",
        "        .reshape(*xx.shape)\n",
        "    )\n",
        "\n",
        "    levels = np.linspace(1e-5, np.max(zz), 10)\n",
        "    ax.contourf(xx, yy, zz, cmap=\"cividis\", alpha=0.8, levels=levels)\n",
        "    ax.contour(xx, yy, zz, cmap=\"cividis\", levels=levels)\n",
        "\n",
        "    ax.set_xlabel(r\"$\\boldsymbol{w}_0$\")\n",
        "    ax.set_ylabel(r\"$\\boldsymbol{w}_1$\")\n",
        "\n",
        "\n",
        "def plot_posterior(ax):\n",
        "    xx, yy, w_plot = get_grid(xlim=(-1.5, 5.5), N=250)\n",
        "    zz = np.zeros(len(w_plot))\n",
        "    for i, w in enumerate(w_plot):\n",
        "        zz[i] = bernoulli_logdensity(y, model(w, X)).sum() -0.5* w.T@w\n",
        "    zz = np.exp(zz).reshape(*xx.shape)\n",
        "    levels = np.linspace(1e-5, np.max(zz), 10)\n",
        "    ax.contourf(xx, yy, zz, cmap=\"cividis\", alpha=0.8, levels=levels)\n",
        "    ax.contour(xx, yy, zz, cmap=\"cividis\", levels=levels)\n",
        "    ax.set_xlabel(r\"$\\boldsymbol{w}_0$\")\n",
        "    ax.set_ylabel(r\"$\\boldsymbol{w}_1$\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjXvaZe6b9XG"
      },
      "outputs": [],
      "source": [
        "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=[12, 4])\n",
        "\n",
        "plot_gaussian(p_params, ax=ax0)\n",
        "plot_posterior(ax=ax1)\n",
        "plot_gaussian(q_params, ax=ax2)\n",
        "\n",
        "ax0.set_title(\"Prior\")\n",
        "ax1.set_title(\"True posterior\")\n",
        "ax2.set_title(\"Variational approx.\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDrHbysDb9XG"
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundary(xx, yy, P, ax):\n",
        "    P = P.reshape(*xx.shape)\n",
        "    levels = [0, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 1]\n",
        "    cs = ax.contour(xx, yy, P, levels, colors=\"k\", linewidths=1.8, zorder=100)\n",
        "    ax.clabel(cs, inline=1, fontsize=10)\n",
        "    cs = ax.contourf(xx, yy, P, levels, cmap=\"Purples_r\", alpha=0.5)\n",
        "\n",
        "\n",
        "xx, yy, Xt = get_grid((-7, 7), N=50)\n",
        "ps = predict_y(sample_gaussian_diagonal, q_params, Xt, rng, Nmc=1000)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=[5, 4])\n",
        "plot_decision_boundary(xx, yy, ps, ax=ax)\n",
        "plot_data(X, y, ax=ax)\n",
        "\n",
        "ax.set_xlabel(r\"$\\boldsymbol{x}_0$\")\n",
        "ax.set_ylabel(r\"$\\boldsymbol{x}_1$\")\n",
        "ax.set_title(\"Predictive density\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4EnZ8dhb9XG"
      },
      "source": [
        "**Exercise:**\n",
        "At convergence, sample 1000 times the ELBO like we did before, and plot it with a boxplot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBuE4yx4b9XG"
      },
      "outputs": [],
      "source": [
        "converged_elbos = pd.DataFrame()\n",
        "n_repetition = 1000\n",
        "converged_elbos[\"Diagonal posterior\"] = np.stack(\n",
        "    [\n",
        "        elbo_fn(q_params, p_params, jax.random.PRNGKey(i), X, y, Nmc=1000)[0]\n",
        "        for i in range(n_repetition)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waIL-c1Xb9XG"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=[4, 3])\n",
        "sns.boxplot(\n",
        "    data=converged_elbos,\n",
        "    whis=np.inf,\n",
        ")\n",
        "ax.axhline(-2.68, color=\"xkcd:red\", label=r\"$p(\\boldsymbol{y}|\\boldsymbol{X})$\")\n",
        "ax.set_title(\"ELBO at convergence\", y=1.02)\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcb78UBLb9XG"
      },
      "source": [
        "# 6. Alternatives to Mean Field Variational Inference\n",
        "\n",
        "As we saw from one of the previous question, the approximation that we used is very rough: it recoves some properties of the true posterior but fails to capture the strong correlation that exists in the parameter space.\n",
        "What we need to do it to increase the complexity and the expressiveness of the variational posterior.\n",
        "The first step that we can do is to introduce a non-diagonal covariance $\\boldsymbol{w} \\sim \\mathcal{N}(\\mu, \\Sigma)$, where the covariance $\\Sigma=LL^\\top$ ($L$ is a lower triangular matrix).\n",
        "\n",
        "Sampling from such distribution is possible again using the reparameterization trick,\n",
        "\n",
        "\\begin{equation}\n",
        "\\tilde{\\boldsymbol{w}} = \\mu + \\mathrm{Tril}(L)\\boldsymbol{\\varepsilon} \\quad \\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(0, \\mathrm{I})\n",
        "\\end{equation}\n",
        "\n",
        "where $\\mathrm{Tril}(\\cdot)$ returns the lower triangular part of the matrix (the other elements are set to 0).\n",
        "\n",
        "**Exercise:**\n",
        "Complete the next functions to model a full covariance Gaussian distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6CVmMRBb9XH"
      },
      "outputs": [],
      "source": [
        "class GaussianFullCov(NamedTuple):\n",
        "    mean: jnp.array\n",
        "    L: jnp.array\n",
        "\n",
        "\n",
        "def sample_gaussian_fullcov(key, params: GaussianFullCov):\n",
        "    \"\"\"\n",
        "    Sample from a Gaussian distribution with full covariance.\n",
        "\n",
        "    Args:\n",
        "        key: Random number generator key.\n",
        "        params: A named tuple containing the mean and Cholesky factor of the Gaussian.\n",
        "    \"\"\"\n",
        "    #@@ COMPLETE @@\n",
        "    # eps =\n",
        "    # out =\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7pt2CXUb9XH"
      },
      "source": [
        "**Exercise:** Try to sample from the distribution and print the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKu-_5b5b9XH"
      },
      "outputs": [],
      "source": [
        "q_params = GaussianFullCov(jnp.zeros(2), jnp.eye(2))\n",
        "\n",
        "print(sample_gaussian_fullcov(jax.random.PRNGKey(1), q_params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T1VSfEib9XH"
      },
      "source": [
        "Now we need to compute the KL divergence between $q$ Gaussian with full covariance and $p$ Gaussian with diagonal covariance.\n",
        "Remember that the expression of the KL divergence between multivariate Gaussians $q = \\mathcal{N}(\\boldsymbol{\\mu}_q, \\Sigma_q)$ and $p = \\mathcal{N}(\\boldsymbol{\\mu}_p, \\Sigma_p)$ is as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathrm{KL}[q || p] =\n",
        "\\frac{1}{2} \\mathrm{Tr}(\\Sigma_p^{-1} \\Sigma_q)\n",
        "+ \\frac{1}{2} (\\mu_p - \\mu_q)^{\\top} \\Sigma_p^{-1} (\\mu_p - \\mu_q)\n",
        "- \\frac{D}{2}\n",
        "+ \\frac{1}{2} \\log\\left( \\frac{\\mathrm{det}\\Sigma_p}{\\mathrm{det}\\Sigma_q} \\right)\n",
        "\\end{equation}\n",
        "\n",
        "**Question:**\n",
        "Given that $q = \\mathcal{N}(\\boldsymbol{\\mu}_q, LL^\\top)$ and $p = \\mathcal{N}(\\boldsymbol{\\mu}_p, \\sigma^2_p\\mathrm{I})$, write the simplified KL divergence.\n",
        "\n",
        "*Hints:*\n",
        "\n",
        "- $\\mathrm{Tr}(\\boldsymbol L \\boldsymbol L^\\top) = \\sum_i\\mathrm{diag}(\\boldsymbol L)_i^2$\n",
        "\n",
        "- $\\log\\mathrm{det}(\\boldsymbol L\\boldsymbol L^\\top) = \\sum_i\\log\\mathrm{diag}(\\boldsymbol L)_i^2$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBh62rilb9XH"
      },
      "source": [
        "Below, you'll find the KL implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ap09SMJb9XH"
      },
      "outputs": [],
      "source": [
        "def kl_full_diag(q_params: GaussianFullCov, p_params: GaussianDiagonal):\n",
        "    \"\"\"\n",
        "    Compute the KL divergence between a Gaussian distribution with full covariance\n",
        "    and a Gaussian distribution with diagonal covariance.\n",
        "    Args:\n",
        "        q_params: A named tuple containing the mean and Cholesky factor of the first Gaussian.\n",
        "        p_params: A named tuple containing the mean and log variance of the second Gaussian.\n",
        "    \"\"\"\n",
        "    #@@ COMPLETE @@\n",
        "    # kl =\n",
        "    return kl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sguo1NZ7b9XH"
      },
      "outputs": [],
      "source": [
        "print(kl_full_diag(q_params, p_params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrkZSC0Tb9XI"
      },
      "source": [
        "**Exercise:**\n",
        "Create the a new elbo to use Gaussian with full covariance. Because we wrote the code for computing the ELBO to be as modular as possible, you can simply change the KL divergence function and the sampling function and everything else will work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usHtijX1b9XI"
      },
      "outputs": [],
      "source": [
        "# @@ COMPLETE @@\n",
        "elbo_fn = create_elbo_fn(\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6cnj_4Vb9XI"
      },
      "source": [
        "**Exercise:**\n",
        "Train this new model exactly the same as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wy-XYC7b9XI"
      },
      "outputs": [],
      "source": [
        "grad_elbo_fn = jax.grad(elbo_fn, has_aux=True)\n",
        "grad_elbo_fn = jax.jit(grad_elbo_fn, static_argnames=(\"Nmc\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMchum2Cb9XI"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "q_params = GaussianFullCov(jnp.zeros(2), jnp.eye(2))\n",
        "\n",
        "elbo_summary = []\n",
        "lik_summary = []\n",
        "kl_summary = []\n",
        "\n",
        "for i in tqdm(range(10000), desc=\"Training ELBO\"):\n",
        "    rng, rng2 = jax.random.split(rng)\n",
        "    q_params_grad, (likelihood, kl) = grad_elbo_fn(\n",
        "        q_params, p_params, rng2, X, y, 100\n",
        "    )\n",
        "    q_params = sgd_update(q_params, q_params_grad, 1e-3)\n",
        "\n",
        "    lik_summary.append(likelihood)\n",
        "    kl_summary.append(kl)\n",
        "    elbo_summary.append(likelihood - kl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gTNIK-yb9XI"
      },
      "source": [
        "**Exercise:**\n",
        "Plot the train curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU8_3ozSb9XI"
      },
      "outputs": [],
      "source": [
        "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=[8, 2.5])\n",
        "\n",
        "ax0.plot(elbo_summary, label=\"ELBO\")\n",
        "ax1.plot(\n",
        "    lik_summary,\n",
        "    color=\"tab:orange\",\n",
        "    label=r\"$E_{q(\\boldsymbol{w})} \\log p(\\boldsymbol{y}|\\boldsymbol{X},\\boldsymbol{w})$\",\n",
        ")\n",
        "ax2.plot(\n",
        "    kl_summary,\n",
        "    color=\"tab:green\",\n",
        "    label=r\"$\\mathrm{KL}[{q(\\boldsymbol{w})}||{p(\\boldsymbol{w})}]$\",\n",
        ")\n",
        "\n",
        "ax0.semilogx()\n",
        "ax1.semilogx()\n",
        "ax2.semilogx()\n",
        "\n",
        "ax0.axhline(-2.68, color=\"xkcd:red\", label=r\"$\\log p(\\boldsymbol{y}|\\boldsymbol{X})$\")\n",
        "ax0.legend(bbox_to_anchor=(1.05, -0.05), loc=\"lower right\")\n",
        "ax1.legend(bbox_to_anchor=(1.05, -0.05), loc=\"lower right\")\n",
        "ax2.legend(bbox_to_anchor=(1.05, -0.05), loc=\"lower right\")\n",
        "\n",
        "ax0.set_xlabel(\"Iteration\")\n",
        "ax1.set_xlabel(\"Iteration\")\n",
        "ax2.set_xlabel(\"Iteration\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFj6CoTEb9XJ"
      },
      "source": [
        "**Exercise:**\n",
        "Plot the densities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOb7ol3bb9XJ"
      },
      "outputs": [],
      "source": [
        "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=[12, 4])\n",
        "\n",
        "plot_gaussian(p_params, ax=ax0)\n",
        "plot_posterior(ax=ax1)\n",
        "plot_gaussian(q_params, ax=ax2)\n",
        "\n",
        "ax0.set_title(\"Prior\")\n",
        "ax1.set_title(\"True posterior\")\n",
        "ax2.set_title(\"Variational approx.\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isBotktCb9XJ"
      },
      "source": [
        "**Exercise:**\n",
        "Plot the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6Jh1D9xb9XJ"
      },
      "outputs": [],
      "source": [
        "xx, yy, Xt = get_grid((-7, 7), N=50)\n",
        "ps = predict_y(sample_gaussian_fullcov, q_params, Xt, rng, Nmc=1000)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=[5, 4])\n",
        "plot_decision_boundary(xx, yy, ps, ax=ax)\n",
        "plot_data(X, y, ax=ax)\n",
        "\n",
        "ax.set_xlabel(r\"$\\boldsymbol{x}_0$\")\n",
        "ax.set_ylabel(r\"$\\boldsymbol{x}_1$\")\n",
        "ax.set_title(\"Predictive density\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2E40fynb9XJ"
      },
      "source": [
        "**Exercise:**\n",
        "Plot the ELBO at convergence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUL9LsUlb9XJ"
      },
      "outputs": [],
      "source": [
        "converged_elbos[\"Full cov. posterior\"] = np.stack(\n",
        "    [\n",
        "        elbo_fn(q_params, p_params, jax.random.PRNGKey(i), X, y, Nmc=1000)[0]\n",
        "        for i in range(n_repetition)\n",
        "    ]\n",
        ")\n",
        "fig, ax = plt.subplots(figsize=[4, 3])\n",
        "sns.boxplot(data=converged_elbos, whis=np.inf)\n",
        "ax.axhline(-2.68, color=\"xkcd:red\", label=r\"$p(\\boldsymbol{y}|\\boldsymbol{X})$\")\n",
        "ax.set_title(\"ELBO at convergence\", y=1.02)\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmO3qw20b9XJ"
      },
      "source": [
        "**Question:**\n",
        "Do you observe something interesting?\n",
        "Remember what the ELBO represents. It is the lower bound of the marginal distribution $p(\\boldsymbol{y}|\\boldsymbol{X})$. Check the first lab on Bayesian linear regression if you don't remember what the marginal distribution measures. Based solely on this value, which model would you choose? Why?    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6BfXVqHb9XJ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibKqY-pbb9XJ"
      },
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "rise": {
      "scroll": true,
      "theme": "sky"
    },
    "toc-autonumbering": false,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}