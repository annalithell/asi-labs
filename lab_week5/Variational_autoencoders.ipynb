{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4015a05",
   "metadata": {},
   "source": [
    "# Advanced Statistical Inference: Variational Autoencoders\n",
    "\n",
    "\n",
    "In this notebook, you will implement a Variational Autoencoder (VAE) for the MNIST dataset.\n",
    "The VAE is a generative model that learns a probabilistic latent representation of data. It consists of two components:\n",
    "\n",
    "- An **encoder** network that approximates the posterior distribution $q(\\mathbf{z}|\\mathbf{x})$, mapping data $\\mathbf{x}$ to a distribution in latent space $\\mathbf{z}$.\n",
    "- A **decoder** network that reconstructs the data from latent variables, approximating the likelihood $p(\\mathbf{x}|\\mathbf{z})$.\n",
    "\n",
    "We will optimize the Evidence Lower Bound (ELBO), which balances reconstruction fidelity and latent space regularization, using stochastic gradient descent and the reparameterization trick.\n",
    "\n",
    "The lab leverages JAX and Flax for differentiable programming and efficient computation.\n",
    "\n",
    "**Important Notes**: It is highly recommended to run this notebook on a GPU or TPU for performance reasons. You can enable GPU/TPU support in Google Colab by going to `Runtime` > `Change runtime type` and selecting `GPU` or `TPU` as the hardware accelerator. Even a small GPU will significantly speed up training compared to a CPU.\n",
    "\n",
    "## Flax Overview\n",
    "\n",
    "* **Flax Overview**:\n",
    "\n",
    "  * Flax is a high-performance neural network library built on top of JAX, developed by Google Research.\n",
    "  * It is designed for flexibility and composability in research settings, with strong support for hardware acceleration via JAX's XLA backend.\n",
    "  * Flax follows a functional programming model, which separates the definition of computation (pure functions) from data (model parameters and other state).\n",
    "  * GPU/TPU support is automatic through JAX: computations are compiled via XLA and dispatched to the available device (CPU, GPU, or TPU) without modifying the model code.\n",
    "  * Example: Unlike PyTorch, where model parameters are typically stored as object attributes, Flax models do not carry their own parameters. Instead, parameters are stored in a dictionary and passed explicitly to functions:\n",
    "\n",
    "    ```python\n",
    "    variables = model.init(rng, x)  # Returns {'params': ...}\n",
    "    y = model.apply(variables, x)\n",
    "    ```\n",
    "\n",
    "* **Core Concepts**:\n",
    "\n",
    "  * The basic building block in Flax is the `flax.linen.Module`, which describes a single layer or component of a model.\n",
    "  * A Flax module is defined using a functional style with explicit inputs and parameter registration via attribute declarations.\n",
    "  * Example:\n",
    "\n",
    "    ```python\n",
    "    class MLP(nn.Module):\n",
    "        features: Sequence[int]\n",
    "\n",
    "        @nn.compact\n",
    "        def __call__(self, x):\n",
    "            for feat in self.features:\n",
    "                x = nn.Dense(feat)(x)\n",
    "                x = nn.relu(x)\n",
    "            return x\n",
    "    ```\n",
    "\n",
    "    This creates a multilayer perceptron where `nn.Dense` layers are registered in a scope, and their parameters are automatically managed.\n",
    "  * Initialization is done by calling `init`, which produces a `variables` dict containing parameters:\n",
    "\n",
    "    ```python\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((1, 32))\n",
    "    mlp = MLP(features=[64, 64])\n",
    "    variables = mlp.init(rng, x)\n",
    "    ```\n",
    "  * Forward evaluation uses `apply`:\n",
    "\n",
    "    ```python\n",
    "    y = mlp.apply(variables, x)\n",
    "    ```\n",
    "  * Device placement is automatic: the arrays returned by `init` and `apply` are JAX DeviceArrays, which are placed on GPU/TPU transparently. No `.to(device)` or manual device context is required.\n",
    "\n",
    "* **State Management and Execution**:\n",
    "\n",
    "  * Flax uses a \"scope\" system to manage variables and submodules during function calls.\n",
    "  * Model state is explicitly stored in collections (e.g., `'params'`) and passed around. This encourages reproducibility and transformation compatibility.\n",
    "  * Integration with JAX transformations is seamless. For example:\n",
    "\n",
    "    * `jax.jit` compiles training steps for fast execution:\n",
    "\n",
    "      ```python\n",
    "      @jax.jit\n",
    "      def train_step(variables, x, y):\n",
    "          def loss_fn(params):\n",
    "              logits = model.apply({'params': params}, x)\n",
    "              loss = cross_entropy_loss(logits, y)\n",
    "              return loss\n",
    "          grads = jax.grad(loss_fn)(variables['params'])\n",
    "          new_params = apply_gradients(variables['params'], grads)\n",
    "          return {'params': new_params}\n",
    "      ```\n",
    "      jit also handles device placement automatically, so the compiled function runs on the most efficient device available.\n",
    "    * `jax.vmap` automatically vectorizes computations over batch dimensions without rewriting the model:\n",
    "\n",
    "      ```python\n",
    "      batched_model = jax.vmap(lambda x: model.apply(variables, x))\n",
    "      y = batched_model(batch_input)\n",
    "      ```\n",
    "  * All model computation and parameters are kept device-agnostic. JAX ensures all operations occur on the most efficient available device, and compiled functions automatically execute on GPU or TPU when present. This simplifies code deployment and accelerates training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80c05c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# If we are on colab runtime, we need to install the datasets library\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    %pip install --quiet datasets huggingface_hub fsspec \n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "from datasets import load_dataset\n",
    "from flax import linen as nn\n",
    "from typing import Any\n",
    "from functools import partial\n",
    "import os\n",
    "from matplotlib import rc\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "# Plot configuration\n",
    "\n",
    "rc(\"font\", **{\"family\": \"sans-serif\", \"sans-serif\": \"DejaVu Sans\"})\n",
    "rc(\"text\", **{\"usetex\": False})\n",
    "rc(\"figure\", **{\"dpi\": 200})\n",
    "rc(\n",
    "    \"axes\",\n",
    "    **{\"spines.right\": False, \"spines.top\": False, \"xmargin\": 0.0, \"ymargin\": 0.05},\n",
    ")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "rng = jax.random.PRNGKey(0)\n",
    "jax.config.update('jax_threefry_partitionable', True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dacc8b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 1. Load and preprocess MNIST\n",
    "\n",
    "We begin by downloading and loading the MNIST dataset using the `datasets` library from Hugging Face, and normalize the image intensities to [0,1]. Each image is 28x28, and we flatten it into a 784-dimensional vector for input into a fully-connected neural network. This preprocessing prepares the data for learning the variational autoencoder latent representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac60bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    ds = load_dataset(\"mnist\")\n",
    "\n",
    "    def normalize(batch):\n",
    "        batch[\"image\"] = batch[\"image\"] / 255.0  # Normalize pixel values to [0, 1]\n",
    "        return batch\n",
    "\n",
    "    train_ds = ds[\"train\"].with_format(\"numpy\").map(normalize, batched=True)\n",
    "    test_ds = ds[\"test\"].with_format(\"numpy\").map(normalize, batched=True)\n",
    "\n",
    "    X_train = np.stack(train_ds[\"image\"]).reshape(-1, 28, 28, 1)\n",
    "    X_test = np.stack(test_ds[\"image\"]).reshape(-1, 28, 28, 1)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "X_train, X_test = load_mnist()\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299cb7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_examples(images, nrows=2, ncols=5, figsize=(10, 4), cmap=\"gray\"):\n",
    "    \"\"\"\n",
    "    Plot a grid of example images.\n",
    "\n",
    "    Args:\n",
    "      images (np.ndarray): Array of images, shape (N, H * W)\n",
    "      nrows (int): Number of rows in the grid.\n",
    "      ncols (int): Number of columns in the grid.\n",
    "      figsize (tuple): Figure size.\n",
    "      cmap (str): Colormap for grayscale images.\n",
    "    \"\"\"\n",
    "    if images.ndim == 2:\n",
    "        images = images.reshape(-1, 28, 28)  # Reshape if single image vector\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < len(images):\n",
    "            img = images[i]\n",
    "            if img.ndim == 2 or (img.ndim == 3 and img.shape[-1] == 1):\n",
    "                ax.imshow(img.squeeze(), cmap=cmap)\n",
    "            else:\n",
    "                ax.imshow(img)\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Plot some training examples\n",
    "plot_examples(X_train[:10], nrows=2, ncols=5, figsize=(10, 4), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e42827",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 2. Define encoder and decoder networks\n",
    "\n",
    "We define the architecture of the encoder and decoder using `flax.linen`. The encoder takes the input image vector $\\mathbf{x} \\in \\mathbb{R}^{28 \\times 28 \\times 1}$ and outputs two vectors: $\\boldsymbol{\\mu}(\\mathbf{x}), \\log \\boldsymbol{\\sigma}^2(\\mathbf{x})$, which parameterize the variational distribution $q(\\mathbf{z}|\\mathbf{x})$. The decoder maps latent variables $\\mathbf{z} \\in \\mathbb{R}^d$ to reconstructed logits for compuuting the likelihood over pixels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmortizationNetwork(nn.Module):\n",
    "    num_layers: int\n",
    "    hidden_dim: int\n",
    "    latent_dim: int\n",
    "    dtype: Any = jnp.bfloat16\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        for _ in range(self.num_layers - 1):\n",
    "            x = nn.Conv(\n",
    "                features=self.hidden_dim,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding=\"SAME\",\n",
    "                dtype=self.dtype,\n",
    "            )(x)\n",
    "            x = nn.LayerNorm(dtype=self.dtype)(x)\n",
    "            x = nn.relu(x)\n",
    "        x = nn.Conv(\n",
    "            features=self.hidden_dim,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(2, 2),\n",
    "            dtype=self.dtype,\n",
    "        )(x)\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten the output\n",
    "        mean = nn.Dense(self.latent_dim, dtype=self.dtype)(x)\n",
    "        logvar = nn.Dense(self.latent_dim, dtype=self.dtype)(x)\n",
    "        return mean, logvar\n",
    "\n",
    "\n",
    "class LikelihoodNetwork(nn.Module):\n",
    "    num_layers: int\n",
    "    hidden_dim: int\n",
    "    output_dim: int\n",
    "    dtype: Any = jnp.bfloat16\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, z):\n",
    "        z = nn.Dense(self.hidden_dim, dtype=self.dtype)(z)\n",
    "        z = z.reshape(z.shape[0], 1, 1, self.hidden_dim)\n",
    "        for _ in range(self.num_layers - 1):\n",
    "            z = nn.ConvTranspose(\n",
    "                features=self.hidden_dim,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(2, 2) if z.shape[2] < 28 else (1, 1), # Up-sampling only if needed, otherwise keep same size\n",
    "                dtype=self.dtype,\n",
    "            )(z)\n",
    "            z = nn.LayerNorm(dtype=self.dtype)(z)\n",
    "\n",
    "        z = nn.ConvTranspose(\n",
    "            features=1,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            dtype=self.dtype,\n",
    "        )(z)\n",
    "        z = nn.Dense(self.output_dim, dtype=self.dtype)(z.reshape(z.shape[0], -1))\n",
    "        z = z.reshape(\n",
    "            z.shape[0], int(np.sqrt(self.output_dim)), int(np.sqrt(self.output_dim)), 1\n",
    "        )\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e16d6",
   "metadata": {},
   "source": [
    "**Exercise**: Create the two models `AmortizationNetwork` and `LikelihoodNetwork` as defined above. The `AmortizationNetwork` will be used for the encoder, and the `LikelihoodNetwork` for the decoder. You can specify the number of layers, hidden dimensions, and latent dimensions as needed, but be reasonable.\n",
    "After, initialize the model parameters using `init` method. The `init` method requires a random key and an example input shape. For the encoder, use an input shape of `(1, 28, 28, 1)` (a single MNIST image), and for the decoder, use an input shape of `(1, latent_dim)` where `latent_dim` is the dimension of the latent space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8339db",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "encoder_num_layers = 2\n",
    "encoder_hidden_dim = 32\n",
    "decoder_num_layers = 5\n",
    "decoder_hidden_dim = 64\n",
    "dtype = \"bfloat16\"\n",
    "\n",
    "# @@ COMPLETE @@\n",
    "# encoder = ...\n",
    "# decoder = ...\n",
    "\n",
    "\n",
    "fake_input = jnp.ones((1, 28, 28, 1), dtype=dtype)  # Example input for encoder\n",
    "fake_latent = jnp.ones((1, latent_dim))  # Example input for decoder\n",
    "\n",
    "# Initialize encoder parameters\n",
    "encoder_params = encoder.init(rng, fake_input)\n",
    "print(encoder.tabulate(rng, fake_input))\n",
    "\n",
    "# Initialize decoder parameters\n",
    "decoder_params = decoder.init(rng, fake_latent)\n",
    "print(decoder.tabulate(rng, fake_latent))\n",
    "\n",
    "# For simplicity, we store parameters in a single dictionary\n",
    "params = {\"encoder\": encoder_params, \"decoder\": decoder_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236468b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 3. Reparameterization trick\n",
    "\n",
    "We want to sample from $\\mathbf{z} \\sim q(\\mathbf{z}|\\mathbf{x}) = \\mathcal{N}(\\boldsymbol{\\mu}, \\operatorname{diag}(\\boldsymbol{\\sigma}^2))$, but to allow gradient-based optimization, we use the reparameterization trick:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = \\boldsymbol{\\mu} + \\boldsymbol{\\sigma} \\odot \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\n",
    "$$\n",
    "\n",
    "This makes the sampling operation differentiable w.r.t. $\\boldsymbol{\\mu}, \\log \\boldsymbol{\\sigma}^2$.\n",
    "\n",
    "**Exercise**: Implement the reparameterization trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(rng, mean, logvar):\n",
    "    \"\"\"\n",
    "    Reparameterization trick to sample from a Gaussian distribution.\n",
    "\n",
    "    Args:\n",
    "        mean (jnp.ndarray): Mean of the Gaussian.\n",
    "        logvar (jnp.ndarray): Log variance of the Gaussian.\n",
    "        rng (jax.random.PRNGKey): Random number generator key.\n",
    "\n",
    "    Returns:\n",
    "        jnp.ndarray: Sampled latent variable.\n",
    "    \"\"\"\n",
    "    eps = jax.random.normal(rng, shape=mean.shape, dtype=mean.dtype)\n",
    "    # @@ COMPLETE @@\n",
    "    # std = ...\n",
    "    # sample = ...\n",
    "    return sample\n",
    "\n",
    "\n",
    "# Test the reparameterization function\n",
    "mean = jnp.array([[0.0, 0.0]])\n",
    "logvar = jnp.array([[0.0, 0.0]])\n",
    "sampled_z = reparameterize(rng, mean, logvar)\n",
    "print(\"Sampled z:\", sampled_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0af908",
   "metadata": {},
   "source": [
    "## 4. Define VAE loss (ELBO)\n",
    "\n",
    "The loss is the negative of the Evidence Lower Bound (ELBO):\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\phi; \\mathbf{x}) = \\mathbb{E}_{q_{\\phi}(\\mathbf{z}|\\mathbf{x})}[ \\log p_\\theta(\\mathbf{x}|\\mathbf{z}) ] - \\operatorname{KL}( q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p(\\mathbf{z}) )\n",
    "$$\n",
    "\n",
    "Assuming $p(\\mathbf{z}) = \\mathcal{N}(0, I)$, $q(\\mathbf{z}|\\mathbf{x}) = \\mathcal{N}(\\boldsymbol{\\mu}, \\operatorname{diag}(\\boldsymbol{\\sigma}^2))$, the KL term is:\n",
    "\n",
    "$$\n",
    "\\operatorname{KL}(q \\| p) = \\frac{1}{2} \\sum_j \\left( \\exp(\\log \\sigma_j^2) + \\mu_j^2 - 1 - \\log \\sigma_j^2 \\right)\n",
    "$$\n",
    "\n",
    "For the reconstruction loss, let's start with the Gaussian likelihood.\n",
    "\n",
    "**Exercise**: Read the code below for computing the ELBO loss function, including the KL divergence and reconstruction loss. Make sure you understand how the loss is computed using the encoder (`AmortizationNetwork`) and decoder (`LikelihoodNetwork`) models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de656fa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "@partial(jax.jit, static_argnames=(\"likelihood\"))\n",
    "def elbo(params, x, rng, kl_weight: float = 1.0, likelihood: str = \"gaussian\"):\n",
    "    \"\"\"\n",
    "    Compute the Evidence Lower Bound (ELBO) for the VAE.\n",
    "\n",
    "    Args:\n",
    "        params (dict): Model parameters containing encoder and decoder.\n",
    "        x (jnp.ndarray): Input data.\n",
    "        rng (jax.random.PRNGKey): Random number generator key.\n",
    "        likelihood (str): Type of likelihood ('gaussian', 'truncated_gaussian', 'bernoulli').\n",
    "        kl_weight (float): Weight for the KL divergence term.\n",
    "    Returns:\n",
    "        jnp.ndarray: ELBO loss value.\n",
    "        jnp.ndarray: Reconstruction loss.\n",
    "        jnp.ndarray: KL divergence.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute mean and log variance from the encoder\n",
    "    mean, logvar = encoder.apply(params[\"encoder\"], x)\n",
    "\n",
    "    # Sample from the latent space using reparameterization trick\n",
    "    z = reparameterize(rng, mean, logvar)\n",
    "\n",
    "    # Compute logits from the decoder\n",
    "    preds = decoder.apply(params[\"decoder\"], z)\n",
    "\n",
    "    # Ensure preds and x have the same dtype\n",
    "    preds = preds.astype(\"float32\").reshape(preds.shape[0], -1)\n",
    "    x = x.astype(\"float32\").reshape(x.shape[0], -1)\n",
    "\n",
    "    # Compute reconstruction loss based on likelihood type\n",
    "    if likelihood == \"gaussian\":\n",
    "        recon_loss = tfd.Normal(loc=preds, scale=1.0).log_prob(x).sum(axis=-1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported likelihood type: {likelihood}\")\n",
    "\n",
    "    # Compute KL divergence\n",
    "    kl = tfd.Normal(loc=mean, scale=jnp.exp(0.5 * logvar)).kl_divergence(\n",
    "        tfd.Normal(loc=0.0, scale=1.0)\n",
    "    )\n",
    "    kl_div = kl_weight * jnp.sum(kl, axis=-1)\n",
    "\n",
    "    # Compute ELBO loss\n",
    "    elbo_loss = -jnp.mean(recon_loss - kl_div)\n",
    "    recon_loss = -jnp.mean(recon_loss)\n",
    "    kl_div = jnp.mean(kl_div)\n",
    "\n",
    "    return elbo_loss, (recon_loss, kl_div)\n",
    "\n",
    "\n",
    "# Test the ELBO function with a batch of data\n",
    "\n",
    "batch_size = 32\n",
    "x_batch = jnp.ones((batch_size, 28, 28, 1))  # Example batch of data\n",
    "elbo_loss, (recon_loss, kl_div) = elbo(params, x_batch, rng)\n",
    "print(\"ELBO Loss:\", elbo_loss)\n",
    "print(\"Reconstruction Loss:\", recon_loss)\n",
    "print(\"KL Divergence:\", kl_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5338d4",
   "metadata": {},
   "source": [
    "## 5. Training loop\n",
    "\n",
    "Great, now we have almost everything we need to train our VAE. We will set up a training loop that iterates over the MNIST dataset, computes the ELBO loss, and updates the model parameters using gradient descent.\n",
    "We need to set up the Adam optimizer (from `optax`). The `train_step` function will compute the gradients of the ELBO with respect to the encoder and decoder parameters and update them.\n",
    "\n",
    "**Exercise**: Read the code below for the training loop. Make sure you understand how the training step is performed, including the use of `jax.grad` to compute gradients and how they are applied using the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc263b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "from flax.training.train_state import TrainState\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"likelihood\",), donate_argnums=(0,))\n",
    "def train_step(state: TrainState, x, rng, kl_weight=1.0, likelihood=\"gaussian\"):\n",
    "    \"\"\"\n",
    "    Perform a single training step for the VAE.\n",
    "\n",
    "    Args:\n",
    "        state (TrainState): Current model state containing parameters and optimizer state.\n",
    "        x (jnp.ndarray): Input data batch.\n",
    "        rng (jax.random.PRNGKey): Random number generator key.\n",
    "        kl_weight (float): Weight for the KL divergence term.\n",
    "        likelihood (str): Type of likelihood ('gaussian', ...)\n",
    "\n",
    "    Returns:\n",
    "        state (TrainState): Updated model state after applying gradients.\n",
    "        tuple: ELBO loss, reconstruction loss, and KL divergence.\n",
    "    \"\"\"\n",
    "    # Define the gradient function for the ELBO \n",
    "    grads_fn = jax.value_and_grad(elbo, has_aux=True)\n",
    "\n",
    "    (elbo_loss, (recon_loss, kl_div)), grads = grads_fn(\n",
    "        state.params, x, rng, kl_weight, likelihood\n",
    "    )   \n",
    "\n",
    "    # Update parameters using the computed gradients\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "\n",
    "    # Return the updated state and the losses\n",
    "    return state, (-elbo_loss, -recon_loss, kl_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b3b8a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "**Exercise**: Run the following training loop for a few epochs to train the VAE on the MNIST dataset. Note that the code is set up to run on a GPU or TPU. A TPU is a chip containing multiple accelerators. In terms of compute, each TPU is equivalent to 8 small GPUs. \n",
    "To take full advantage of GPUs and TPUs, we can parallelize the training across multiple devices. For example, you can split the batch of images across multiple devices, each device processing a portion of the batch independently and then aggregating the results. \n",
    "This is known as **data parallelism**. The code below automatically handles this case. If you are running on a single device, it will simply run the training loop on that device. If you are running on a TPU, it will automatically split the batch across the 8 accelerators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d175a59b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from jax.sharding import PartitionSpec as P, NamedSharding\n",
    "\n",
    "# Set up sharding for distributed training\n",
    "# A mesh is a abstraction for the devices we are using\n",
    "# A mesh can have multiple dimensions, depending on how we want to partition our data/model\n",
    "# Here we use a single dimension \"batch\" for data parallelism\n",
    "mesh = jax.make_mesh((jax.local_device_count(), ), (\"batch\",)) \n",
    "\n",
    "# Set up 2 strategies for sharding:\n",
    "# - sharded: to distribute the \"batch\" dimension across devices (e.g. split the batch across devices)\n",
    "# - replicated: to replicate and synchronize the data across all devices (e.g. to copy the model parameters)\n",
    "sharded = NamedSharding(mesh, P(\"batch\"))\n",
    "replicated = NamedSharding(mesh, P())\n",
    "\n",
    "# Initialize the optimizer\n",
    "# We use Adam optimizer\n",
    "optim = optax.adam(learning_rate=1e-3, b1=0.9, b2=0.999, eps=1e-8)\n",
    "\n",
    "# Initialize the train state\n",
    "# The train state contains the model parameters and the optimizer, \n",
    "# and (optionally) the forward function of the model\n",
    "# Since we have two networks (encoder and decoder), we are not using `apply_fn` here to avoid confusion.\n",
    "state = TrainState.create(params=params, tx=optim, apply_fn=None)\n",
    "\n",
    "num_epochs = 1000\n",
    "batch_size = 1024 * jax.device_count()  # Adjust batch size based on number of devices\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "steps_per_epoch = n_train // batch_size\n",
    "\n",
    "losses = []\n",
    "\n",
    "state = jax.device_put(state, replicated) # The state is replicated across devices\n",
    "with tqdm(total=num_epochs, desc=\"Training VAE\", unit=\"epoch\", colour=\"blue\") as pbar:\n",
    "    for epoch in range(num_epochs):\n",
    "        perm = np.random.permutation(n_train)\n",
    "        _loss = 0.0\n",
    "        for step in range(steps_per_epoch):\n",
    "            rng, subkey = jax.random.split(rng)\n",
    "            \n",
    "            batch_idx = perm[step * batch_size : (step + 1) * batch_size]\n",
    "            batch = X_train[batch_idx]\n",
    "            \n",
    "            batch = jax.device_put(batch, sharded) # The batch is sharded across devices\n",
    "            \n",
    "            state, (loss, recon_loss, kl_div) = train_step(state, batch, subkey)\n",
    "            _loss += (loss)\n",
    "        loss = _loss / steps_per_epoch\n",
    "\n",
    "        losses.append(loss)\n",
    "        pbar.set_postfix_str(f'loss={loss:.4f}')\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c4189",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 6. Generate Samples from the VAE\n",
    "\n",
    "Once training is complete, we can use the decoder network to generate new samples from the learned generative model.\n",
    "\n",
    "The procedure follows from the probabilistic formulation of the generative model:\n",
    "\n",
    "1. Sample $\\mathbf{z} \\sim p(\\mathbf{z}) = \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$, where $\\mathbf{z} \\in \\mathbb{R}^d$.\n",
    "2. Decode $\\mathbf{z}$ to generate $\\mathbf{x}_{\\text{logits}} = f_{\\text{decoder}}(\\mathbf{z})$.\n",
    "3. If using a Gaussian likelihood: sample or visualize $\\mathbf{x}_{\\text{logits}}$ directly as reconstructions.\n",
    "   If using Bernoulli likelihood: apply sigmoid to $\\mathbf{x}_{\\text{logits}}$ and sample binary images or threshold.\n",
    "\n",
    "Sampling directly from $p(\\mathbf{x}) = \\int p(\\mathbf{x}|\\mathbf{z}) p(\\mathbf{z}) d\\mathbf{z}$ is intractable, but the decoder learned to approximate $p(\\mathbf{x}|\\mathbf{z})$.\n",
    "\n",
    "**Exercise**: Generate and visualize samples from the decoder. Sample $\\mathbf{z} \\sim \\mathcal{N}(0, I)$ and decode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(\n",
    "    decoder, decoder_params, rng, num_samples=10, latent_dim=4, likelihood=\"gaussian\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate samples from the VAE by decoding samples from the prior.\n",
    "\n",
    "    Args:\n",
    "        decoder: Flax decoder module.\n",
    "        decoder_params: Decoder parameters.\n",
    "        rng: PRNGKey for randomness.\n",
    "        num_samples: Number of samples to generate.\n",
    "        latent_dim: Dimensionality of latent space.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Decoded images in shape (num_samples, 28, 28).\n",
    "    \"\"\"\n",
    "    # Sample latent variables from standard Gaussian\n",
    "    rng, z_key = jax.random.split(rng)\n",
    "    z_samples = jax.random.normal(z_key, shape=(num_samples, latent_dim))\n",
    "\n",
    "    # Decode latent vectors into image space\n",
    "    images = decoder.apply(decoder_params, z_samples)\n",
    "    if likelihood != \"gaussian\":\n",
    "        images = jax.nn.sigmoid(images)\n",
    "    images_np = np.array(images).reshape(-1, 28, 28).astype(np.float32)\n",
    "    return images_np\n",
    "\n",
    "\n",
    "# Generate and plot samples\n",
    "rng, sample_key = jax.random.split(rng)\n",
    "sampled_images = generate_samples(\n",
    "    decoder, state.params[\"decoder\"], sample_key, num_samples=10, latent_dim=latent_dim\n",
    ")\n",
    "fig = plot_examples(sampled_images, nrows=2, ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7fa88b",
   "metadata": {},
   "source": [
    "\n",
    "## Visualize Latent Space\n",
    "\n",
    "We can visualize the learned latent space by encoding a grid of points in the latent space and decoding them to generate images. This allows us to see how the model organizes different digits or classes in the latent space.\n",
    "Remember that the latent space is a continuous representation, so we can interpolate between points to see how the model transitions between latent representations.\n",
    "\n",
    "\n",
    "**Exercise**: Create a grid of points in the latent space, decode them, and visualize the generated images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4af72c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "    # Create a meshgrid of latent space coordinates\n",
    "    grid_z = np.dstack(np.meshgrid(grid_x, grid_y)).reshape(-1, 2)\n",
    "    \n",
    "    # Decode all points in the grid at once (batch computation)\n",
    "    x_decoded = decoder.apply(state.params[\"decoder\"], grid_z)\n",
    "    \n",
    "    # Reshape and place in the figure\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            idx = i * n + j\n",
    "            digit = x_decoded[idx].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"$z_0$\")\n",
    "    plt.ylabel(\"$z_1$\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot the latent space\n",
    "plot_latent_space(decoder, n=30, figsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf79334a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "## Likelihood choices\n",
    "The choice of likelihood function in the VAE decoder can significantly affect the model's performance and the quality of generated samples. \n",
    "So far, we have used a Gaussian likelihood, which is suitable for continuous data. However, we are modeling pixel values in the range [0, 1], which suggests that the Gaussian likelihood may not be the best choice due to its unbounded nature.\n",
    "Instead, we can consider using three different likelihood functions:\n",
    "1. **Bernoulli**: This is a discrete distribution suitable for binary data, where each pixel is treated as a Bernoulli random variable. It can be used with a sigmoid activation to model pixel probabilities, but it requires that the data is binary (0 or 1). This is still not ideal for continuous data, but it is used in practice by binarizing the pixel values.\n",
    "1. **Continuous Bernoulli**: This is a continuous relaxation of the Bernoulli distribution, which allows for modeling continuous data in the range [0, 1]. It is defined as a continuous distribution that can model pixel values in the range [0, 1] without binarization. It is suitable for continuous data and can be used with a sigmoid activation to model pixel probabilities.\n",
    "1. **Truncated Gaussian**: This is a Gaussian distribution truncated to the range [a, b]. It can handle continuous data while respecting the pixel value bounds. This is a more appropriate choice for modeling pixel values in images\n",
    "\n",
    "\n",
    "**Exercise**: Modify the ELBO function above to support these three likelihood functions. Note that all three likelihoods are implemented in `tensorflow_probability`, so directly use them to compute the reconstruction loss. You can use the `likelihood` argument to specify which likelihood function to use. Remember to perform the necessary transformations to ensure the outputs of the decoder are compatible with the chosen likelihood function. For example, you may need to apply a sigmoid activation to the decoder outputs to ensure they are in the range [0, 1].\n",
    "The KL divergence term remains the same for all likelihoods, as it is independent of the likelihood choice.\n",
    "\n",
    "\n",
    "**Exercise**: After modifying the ELBO function, train the VAE with each likelihood function and visualize the generated samples. Compare the quality of samples generated by each likelihood function and discuss the differences."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
